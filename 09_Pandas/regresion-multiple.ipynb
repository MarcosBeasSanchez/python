{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cuaderno de trabajo de:__ Nombre Apellido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal Múltiple\n",
    "\n",
    "Vamos a continuar con el capítulo 3 del libro [\"Introduction to Statistical Learning\"](http://www-bcf.usc.edu/~gareth/ISL/), ahora con la sección 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.metrics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    " \n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos\n",
    "\n",
    "Cargamos los conjuntos de datos que vamos a usar\n",
    "\n",
    "Los conjuntos de datos están en la web del libro (pero ya están descargados)\n",
    "http://www-bcf.usc.edu/~gareth/ISL/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   Radio      200 non-null    float64\n",
      " 2   Newspaper  200 non-null    float64\n",
      " 3   Sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 7.8 KB\n"
     ]
    }
   ],
   "source": [
    "advertising = pd.read_csv('advertising.csv', usecols=[1,2,3,4], na_values='?').dropna()  \n",
    "# na_values='?').dropna()  borra las filas y ciolumnas que tienen Null/NaN \n",
    "advertising.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión y ajuste de modelos\n",
    "\n",
    "El análisis de regresión consiste en encontrar un  **modelo** que relaciona los valores medidos de una variable **objetivo** (tb se llama la **respuesta**) en función de un conjunto de variables **explicativas** (tb **variables predictoras**, o **variables explicativas**, o **regresores**).\n",
    "\n",
    "Los valores medidos en el mundo real nunca se ajustan de forma perfecta a un modelo, debido en primer lugar a errores de medida, pero también a que cualquier modelo matemático es una *simplificación* del mundo real, y si tuviera en cuenta todos los factores que influyen en un conjunto de variables, sería inmanejable.\n",
    "\n",
    "Por tanto, no tiene sentido aspirar a encontrar un modelo que prediga exactamente los valores medidos, y debemos admitir que el modelo cometerá un cierto error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo útil encuentra una relación funcional sencilla en conjuntos de pocas variables. Se trata de explicar una variable objetivo en función de otro conjunto de variables mejor conocidas o más fáciles de medir. El  **análisis de regresión**  (más exactamente, el análisis de regresión  *paramétrico*) permite encontrar un modelo explicativo en dos etapas:\n",
    "\n",
    "\n",
    " 1. Nuestro conocimiento del tema en cuestión nos permite escribir un modelo que afirma que la variable  *Y*  es una función de las variables $X_1,\\dots,X_p$. La variable  *Y* se suele llamar la **respuesta** y las variables  $X_1,\\dots,X_p$ se llaman  **variables predictoras**. La forma exacta de la función no está fijada a priori, sino que depende de unos pocos  **parámetros**  libres.\n",
    " \n",
    " Por ejemplo, para la **regresión lineal**, el modelo es\n",
    " $$\n",
    " Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon\n",
    " $$\n",
    " donde $\\beta_0,\\dots,\\beta_p$ son los parámetros y $\\epsilon$ es un error que no podemos explicar dentro de este modelo.\n",
    " \n",
    " 2. **Ajustamos el modelo** a los datos de que disponemos, eligiendo los valores de los parámetros para los que la distancia entre los valores medidos de la variable  *Y*  y los valores predichos aplicando el modelo minimizan el error cometido. El error que se suele minimizar es el error cuadrático (**residual sum of squares**):\n",
    "$$\n",
    "RSS = e_1^2 + e_2^2 + \\dots + e_n^2\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "e_1 = y_1 - (\\beta_0 + \\beta_1 X_1^1 + ... + \\beta_p X_p^1), \\dots e_n = y_n - (\\beta_0 + \\beta_1 X_1^n  + ... + \\beta_p X_p^n).\n",
    "$$\n",
    "Es decir, entre todas las posibles combinaciones de coeficientes $(\\beta_0,\\dots,\\beta_p)$ nos quedamos con aquella combinación $(\\hat{\\beta_0},\\hat{\\beta_1},\\dots,\\hat{\\beta_1})$ que minimiza el RSS, y hemos obtenido la  **regresión lineal por mínimos cuadrados** (**least squares**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Inversión en publicidad\n",
    "\n",
    "Hacer regresión múltiple consiste en encontrar una función lineal de las variables predictoras que aproxima la función objetivo:\n",
    "\n",
    "$$\n",
    "Sales\\approx \\beta_0 + \\beta_1\\times TV  + \\beta_2\\times radio  + \\beta_3\\times newspaper\n",
    "$$\n",
    "\n",
    "Si incorporamos el término de error, podemos sustituir el signo de aproximación $\\approx$ por uno de igualdad:\n",
    "\n",
    "$$\n",
    "Sales = \\beta_0 + \\beta_1\\times TV  + \\beta_2\\times radio  + \\beta_3\\times newspaper + \\varepsilon\n",
    "$$\n",
    "\n",
    "\n",
    "que minimiza el error cuadrático. Es cualitiva y cuantitivamente distinto de ajustar modelos por separado para cada variable predictora:\n",
    "\n",
    "$$\n",
    "Sales = \\beta_0^{TV} + \\beta_1^{TV}\\times TV + \\varepsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "Sales = \\beta_0^R + \\beta_1^R\\times radio  + \\varepsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "Sales = \\beta_0^N + \\beta_1^{N}\\times newspaper + \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal múltiple con scikit_learn\n",
    "\n",
    "  1. Definimos un objeto de tipo \"LinearRegression\"\n",
    "\n",
    "```python\n",
    "regr = skl_lm.LinearRegression()\n",
    "```\n",
    "\n",
    "  2. El método ``fit`` **\"ajusta\"** la función lineal, encontrando los valores de $(\\beta_0, \\beta_1, \\dots, \\beta_p)$ para los que el error cuadrático cometido es menor. Necesita dos argumentos:\n",
    "      - Un **array 2D de numpy** o un **DataFrame** X con las variables predictoras. No acepta una serie ni un array 1D.\n",
    "      - Una **Serie** y con la variable objetivo.\n",
    "\n",
    "```python\n",
    "X = advertising[['TV', 'Radio', 'Newspaper']]\n",
    "y = advertising.Sales\n",
    "\n",
    "regr.fit(X,y)\n",
    "```\n",
    "\n",
    "y ya tenemos el objeto ``regr`` que contiene la recta ajustada por mínimos cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.938889369459412\n",
      "[ 0.04576465  0.18853002 -0.00103749]\n"
     ]
    }
   ],
   "source": [
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "X = advertising[['TV', 'Radio', 'Newspaper']]\n",
    "y = advertising.Sales\n",
    "\n",
    "regr.fit(X,y)\n",
    "\n",
    "print(regr.intercept_)  #beta0\n",
    "print(regr.coef_)       #beta1 .. betap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predecir \n",
    "\n",
    "Ahora que el modelo está ajustado, podemos predecir la cantidad de ventas, conocido el valor de las variables predictoras.\n",
    "\n",
    "```python\n",
    "regr.predict([[inv_TV, inv_Radio, inv_Newspaper]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.84166996945941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.938889369459412 + 0.04576465*200 +  0.18853002*20 -0.00103749*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.84166894])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#El orden de (inv_TV, inv_Radio, inv_Newspaper) es importante: \n",
    "#en el mismo orden que al llamar a regr.fit(...)\n",
    "regr.predict([[200,20,20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos llamar a ``regr.predict()`` con un DataFrame como argumento, por ejemplo para predecir el nivel de ventas para distintas asignaciones alternativas de un presupuesto de 300k para inversión en publicidad.\n",
    "\n",
    "**Atención**: es necesario que las columnas en el DataFrame aparezcan *en el mismo orden* que usamos al entrenar el modelo. Se debe a que ``scikit-learn`` fue concebida pensando en ``numpy``, antes de que ``pandas`` se hiciera tan popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.14012963, 15.0254298 , 13.1297547 , 13.15050456])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No es necesario que tenga la respuesta\n",
    "advertising_future = pd.DataFrame(\n",
    "    [\n",
    "        [100,30,30],\n",
    "        [100,40,30],\n",
    "        [100,30,40],\n",
    "        [100,30,20]        \n",
    "    ],\n",
    "    columns=['TV', 'Radio', 'Newspaper']\n",
    ")\n",
    "regr.predict(advertising_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels \n",
    "\n",
    "Vamos a usar también la librería statsmodel, que imita la sintaxis de la regresión lineal en ``R``.\n",
    "\n",
    "La fórmula ``Sales ~ TV + Radio`` significa que busca el modelo de regresión lineal:\n",
    "$$\n",
    "Sales\\approx \\beta_0 + \\beta_1\\times TV + \\beta_2 \\times Radio + \\varepsilon\n",
    "$$\n",
    "\n",
    " - Ajustamos el modelo $Sales\\approx \\beta_0 + \\beta_1\\times TV + \\beta_2 \\times Radio+ \\varepsilon$ usando el DataFrame ``advertising``.\n",
    " \n",
    "```python\n",
    "recta = smf.ols('Sales ~ TV + Radio', advertising).fit()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio', advertising).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar el modelo para hacer predicciones\n",
    "\n",
    "Usando **statsmodels**, necesitamos un DataFrame con las columnas predictoras, no es necesario que tenga la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    TV  Radio  Newspaper\n",
       "0  100     30         30\n",
       "1  100     40         30\n",
       "2  100     30         40\n",
       "3  100     30         20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertising_future = pd.DataFrame(\n",
    "    [\n",
    "        [100,30,30],\n",
    "        [100,40,30],\n",
    "        [100,30,40],\n",
    "        [100,30,20]        \n",
    "    ],\n",
    "    columns=['TV', 'Radio', 'Newspaper']\n",
    ")\n",
    "advertising_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13.136408\n",
       "1    15.016350\n",
       "2    13.136408\n",
       "3    13.136408\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.predict(advertising_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    TV  Radio  Newspaper\n",
       "0  100     30         30\n",
       "1  100     40         30\n",
       "2  100     30         40\n",
       "3  100     30         20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertising_future = pd.DataFrame({\n",
    "        'TV':[100,100,100,100],\n",
    "        'Radio':[30,40,30,30],\n",
    "        'Newspaper':[30,30,40,20]\n",
    "})\n",
    "advertising_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13.136408\n",
       "1    15.016350\n",
       "2    13.136408\n",
       "3    13.136408\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.predict(advertising_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13.136408\n",
       "1    15.016350\n",
       "2    13.136408\n",
       "3    13.136408\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertising_future = pd.DataFrame(\n",
    "    [\n",
    "        [100,30,30],\n",
    "        [100,40,30],\n",
    "        [100,30,40],\n",
    "        [100,30,20]        \n",
    "    ],\n",
    "    columns=['TV', 'Radio', 'Newspaper']\n",
    ")\n",
    "\n",
    "est.predict(advertising_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21.596148\n",
       "1    21.471774\n",
       "2    19.059659\n",
       "3    16.647544\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TV': [100, 200, 250, 300],\n",
    "    'Radio': [75, 50, 25, 0],\n",
    "    'Newspaper': [75, 50, 25, 0]\n",
    "})\n",
    "est.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretando el modelo ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio + Newspaper', advertising).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 06 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:41:36</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.897\n",
       "Model:                            OLS   Adj. R-squared:                  0.896\n",
       "Method:                 Least Squares   F-statistic:                     570.3\n",
       "Date:                Wed, 06 Jan 2021   Prob (F-statistic):           1.58e-96\n",
       "Time:                        10:41:36   Log-Likelihood:                -386.18\n",
       "No. Observations:                 200   AIC:                             780.4\n",
       "Df Residuals:                     196   BIC:                             793.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
       "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
       "Radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
       "Newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
       "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
       "Kurtosis:                       6.332   Cond. No.                         454.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio + Newspaper', advertising).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalo de confianza\n",
    "\n",
    "En la tabla resumen de statsmodel, podemos observar dos columnas ``[0.025 \t0.975]``, que delimitan un **intervalo de confianza al 95%** para cada coeficiente.\n",
    "\n",
    "No vamos a estudiar los intervalos de confianza en detalle, sólo diremos que:\n",
    "\n",
    " - Representan **un intervalo de _\"valores razonables\"_ para el valor de cada coeficiente** $\\beta_0,\\dots \\beta_p$.\n",
    " - **No significa** que _\"la probabilidad de que $\\beta_j$ esté dentro del intervalo es 0.95\"_.\n",
    " - No hay una distribución de probabilidad conjunta para los valores de los coeficientes. La definición, y la lógica detrás de los intervalos de confianza, es distinta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastes de hipótesis\n",
    "\n",
    "No vamos a estudiar los contrastes de hipótesis en detalle, sólo diremos que:\n",
    "\n",
    " - Lanzamos una hipótesis binaria como:\n",
    "     - \"Esta muestra es una extracción aleatoria independiente de una Normal con media 0 y desviación típica 20 cm\".\n",
    "     - \"Estas dos muestras provienen de la misma distribución\".\n",
    "     - \"El coeficiente de X en la regresión $Y\\approx \\beta_0 + \\beta_1 X + \\varepsilon$ es distinto de 0\".\n",
    " - No asignamos una probabilidad a la hipótesis, sino que la respuesta es \"sí (hay evidencia significativa de que la hipótesis es correcta)\" o \"no (no hay evidencia significativa de que la hipótesis es correcta)\".\n",
    " \n",
    "> - Es necesario poner mucha atención en distinguir _\"**no** hay evidencia significativa de que la hipótesis es correcta\"_ de _\"hay evidencia significativa de que la hipótesis **no** es correcta\"_.\n",
    "\n",
    " - Sin embargo, la confianza en la respuesta se mide con un **p-valor**, que **no es una probabilidad**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraste de hipótesis: \"¿Podria este coeficiente ser cero?\"\n",
    "\n",
    "Observamos ahora las columnas ``std err \tt \tP>|t|``:\n",
    " - **std err** es una estimación del error estándar cometido en la estimación de cada coeficiente\n",
    " - **t**: el [estadístico t](https://en.wikipedia.org/wiki/T-statistic) es el ratio entre la estimación del coeficiente y el error estándar.\n",
    " - **P>|t|**: el **p-valor** asociado al contraste de hipótesis \"¿Es posible que el coeficiente en realidad sea 0?\".\n",
    "\n",
    "   - La **hipótesis nula**: El valor del coeficiente $\\beta_j$ es 0.\n",
    "   - La **hipótesis alternativa**: El valor del coeficiente $\\beta_j$ es **distinto de** 0.\n",
    "\n",
    "> - Un valor bajo del p-valor indica que hay evidencia de que el coeficiente es distinto de cero.\n",
    "> - Un valor alto del p-valor indica que no hay evidencia de que el coeficiente sea distinto de cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ajustamos el modelo lineal que depende sólo de Newspaper\n",
    "\n",
    "$$\n",
    "Sales\\approx \\beta_0 + \\beta_3\\times newspaper + \\varepsilon,\n",
    "$$\n",
    "\n",
    "nos sale que la pendiente de la recta es positiva con un p-valor del 0.1%, pero si ajustamos el modelo lineal completo:\n",
    "\n",
    "$$\n",
    "Sales\\approx \\beta_0 + \\beta_1\\times TV  + \\beta_2\\times radio  + \\beta_3\\times newspaper + \\varepsilon\n",
    "$$\n",
    "\n",
    "la pendiente $\\beta_3$ es muy próxima a 0 (el p-valor es muy alto, el intervalo de confianza contiene a 0...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    9.3116</td> <td>    0.563</td> <td>   16.542</td> <td> 0.000</td> <td>    8.202</td> <td>   10.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.2025</td> <td>    0.020</td> <td>    9.921</td> <td> 0.000</td> <td>    0.162</td> <td>    0.243</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ Radio', advertising).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   12.3514</td> <td>    0.621</td> <td>   19.876</td> <td> 0.000</td> <td>   11.126</td> <td>   13.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>    0.0547</td> <td>    0.017</td> <td>    3.300</td> <td> 0.001</td> <td>    0.022</td> <td>    0.087</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ Newspaper', advertising).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tabla de resumen para regresión múltiple, aparece una fila para cada coeficiente del modelo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio + Newspaper', advertising).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué sentido tiene que el coeficiente de **newspaper** sea positivo en la regresión simple y cercano a 0 en la regresión múltiple? Se puede interpretar así:\n",
    "\n",
    "> En aquellos países en los que se invierte más en anuncios en periódicos, también se suele invertir en TV y radio (lo comprobamos al observar que la correlación entre **newspaper** y **Radio** es del 35%). El modelo lineal múltiple indica que los anuncios en TV y radio son eficaces (aumentan las ventas), mientras que los anuncios en periódicos no. Sin embargo, si hacemos la regresión simple, resulta que los países en los que más se invierte más en anuncios en periódicos tienen más ventas que aquellos en los que se invierte menos, pero es debido a que también se invierte más en Radio, y no es causa directa de los anuncios en periódicos.\n",
    "\n",
    "Un ejemplo clásico:\n",
    "> Ajustamos un modelo lineal a $Y$ (ataques de tiburones) contra $X_1$ (ventas de helados en la playa) y encontramos una pendiente (correlación) positiva: a mayor ventas de helados, más ataques de tiburones. Obviamente no hay relación de causalidad entre ambas variables, pero en este caso podemos encontrar una causa que explica esta correlación: cuanta más gente en la playa ($X_2$), más ventas de helados y más ataques a tiburones. Una regresión múltiple $Y\\sim X_1,X_2$, no muestra relación positiva entre $X_1$ e $Y$, y sí lo hace entre $X_2$ e $Y$.\n",
    "\n",
    "Para más información, puedes leer sobre [factores de confusión](https://en.wikipedia.org/wiki/Confounding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 TV     Radio  Newspaper     Sales\n",
       "TV         1.000000  0.054809   0.056648  0.782224\n",
       "Radio      0.054809  1.000000   0.354104  0.576223\n",
       "Newspaper  0.056648  0.354104   1.000000  0.228299\n",
       "Sales      0.782224  0.576223   0.228299  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertising.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo decidimos si un modelo es bueno?\n",
    "\n",
    "Supongamos que el mejor modelo lineal que hemos encontrado es \n",
    "$$\n",
    "y=f(\\mathbf{x})+\\epsilon=\\beta_0 + x_1\\beta_1 +\\dots +x_p\\beta_p+\\epsilon,\\qquad \\mathbf{x}=(x_1,\\dots,x_p).\n",
    "$$\n",
    "\n",
    " - **TSS**: Total sum of squares: $\\Sigma_i (y_i-\\bar{y})^2$ (sumamos el cuadrado de la diferencia entre el dato $y_i$ y la media $\\bar{y}$)\n",
    " - **RSS**: Residual sum of squares:  $\\Sigma_i (y_i-f(\\mathbf{x}_i))^2$ (sumamos el cuadrado de la diferencia entre el dato $y_i$ y la predicción $f(\\mathbf{x}_i)$ usando nuestro modelo)\n",
    " - **RSS/TSS**: cociente entre la \"varianza residual\" y la \"varianza total\"\n",
    " - **R-cuadrado**: \"porcentaje de la varianza que el modelo explica\". \n",
    "$$\n",
    "R^2 = 1 - \\frac{RSS}{TSS}\n",
    "$$\n",
    "\n",
    "```python\n",
    "#Calcula R^2 con scikit-learn\n",
    "regr.score(X,y)\n",
    "```\n",
    "\n",
    "```python\n",
    "#Devuelve R^2 para el modelo ajustado con statsmodels\n",
    "est.rsquared\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972106381789522"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calcula R^2 con scikit-learn\n",
    "regr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972106381789522"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Devuelve R^2 para el modelo ajustado con statsmodels\n",
    "est.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estadístico $R^2$ es igual al cuadrado de la correlación entre la respuesta y el valor del modelo lineal ajustado.\n",
    "$$\n",
    "R^2 = Cor(Y,f(X))^2\n",
    "$$\n",
    "Sin embargo, es necesario ajustar el modelo para calcular esa correlación, no es una correlación entre las variables originales, como ocurría en el caso de la regresión lineal simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando modelos\n",
    "\n",
    "El estadístico $R^2$ siempre aumenta al añadir variables, pero ¿añadir más y más variables da lugar siempre a un modelo mejor?\n",
    "\n",
    "A menudo, *la ganancia marginal por incorporar otra variable no compensa las desventajas*. Un modelo con más variables, o con términos no lineales:\n",
    "\n",
    " 1. es más complejo, y nos impide usar el modelo de ciertas formas.\n",
    " 2. **generaliza** peor: aunque ajuste muy bien a los datos que tenemos, ajusta peor a datos nuevos.\n",
    "\n",
    "La semana que viene hablaremos despacio sobre los temas de **sobreajuste**, **validación** y **sesgo vs varianza**.\n",
    "Por el momento, sólo mencionaremos que hay medidores de bondad de ajuste alternativos al **R-squared** que intentan buscar un equilibrio entre un buen ajuste y un modelo sencillo con pocas variables predictoras:\n",
    "\n",
    " - **Adj. R-squared** aumenta cuando decrece el error, pero disminuye cuando incluimos más variables predictoras. De hecho, la fórmula es sencilla:\n",
    " \n",
    "$$\n",
    "{\\bar {R}}^{2}={1-(1-R^{2}){n-1 \\over n-p-1}}\n",
    "$$\n",
    "\n",
    " - **AIC** y **BIC** disminuyen cuando decrece el error, pero aumentan cuando incluimos más variables predictoras. Se definen de forma similar, pero el BIC penaliza más duramente los modelos con más parámetros.\n",
    " \n",
    "> _Tanto el AIC como el BIC solo sirven para comparar modelos. No importa si son grandes o pequeños._\n",
    "> \n",
    "> Si el AIC para el modelo ``A`` vale a y el AIC para el modelo ``B`` vale b, entonces es $\\exp\\left(\\frac{a-b}{2}\\right)$ veces más probable que el modelo A minimize la pérdida de información que el modelo B (si son igual de probables a priori). Este ratio es exactamente el mismo si $a=2, b=1$ o si $a=3001, b=3000$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando modelos en el ejemplo de prensa\n",
    "\n",
    "Tras observar que el coeficiente de **newspaper** tiene un p-valor alto (o que 0 está en un intervalo de confianza), probamos a usar el modelo que sólo usa TV y Radio.\n",
    "\n",
    "Comparamos los resultados de ambos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 06 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:41:36</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio + Newspaper', advertising).fit()\n",
    "est.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   859.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 06 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>4.83e-98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:41:36</td>     <th>  Log-Likelihood:    </th> <td> -386.20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   778.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   788.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio', advertising).fit()\n",
    "est.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que sin la variable **newspaper** obtenemos casi el mismo valor de R-squared (explicamos el mismo porcentaje de la varianza). Los indicadores AIC y BIC disminuyen ligeramente, confirmando que es buen movimiento. El _\"adjusted $R^2$\"_ es casi igual en ambos casos: es un criterio que no es muy crítico con el aumento del número de variables predictoras. De los tres criterios, el BIC es el que más penaliza el aumento de variables redundantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables categóricas\n",
    "\n",
    "> ¿Podemos incorporar variables cualitativas a una regresión?\n",
    "\n",
    "En el dataset siguiente, se trata de predecir el balance de una tarjeta de crédito en función de varias variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender Student  \\\n",
       "0           1   14.891   3606     283      2   34         11    Male      No   \n",
       "1           2  106.025   6645     483      3   82         15  Female     Yes   \n",
       "2           3  104.593   7075     514      4   71         11    Male      No   \n",
       "3           4  148.924   9504     681      3   36         11  Female      No   \n",
       "4           5   55.882   4897     357      2   68         16    Male      No   \n",
       "\n",
       "  Married  Ethnicity  Balance  \n",
       "0     Yes  Caucasian      333  \n",
       "1     Yes      Asian      903  \n",
       "2      No      Asian      580  \n",
       "3      No      Asian      964  \n",
       "4     Yes  Caucasian      331  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.read_csv('credit.csv')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, podemos intentar decidir si el género es una buena variable predictora, ajustando un modelo:\n",
    "\n",
    "> Balance ~ Gender\n",
    "\n",
    "que es lo mismo que ajustar\n",
    "\n",
    "$$\n",
    "\\text{Balance} = \\beta_0 + \\beta_1 x_{\\text{Gender}}  + \\varepsilon\n",
    "$$\n",
    "\n",
    "donde $x_{\\text{Gender}}$ vale 1 si es \"Male\" y 0 si es \"Female\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00046113296449623586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>  509.8031</td> <td>   33.128</td> <td>   15.389</td> <td> 0.000</td> <td>  444.675</td> <td>  574.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender[T.Female]</th> <td>   19.7331</td> <td>   46.051</td> <td>    0.429</td> <td> 0.669</td> <td>  -70.801</td> <td>  110.267</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Balance ~ Gender', credit).fit()\n",
    "print(est.rsquared)\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conclusión parece ser que no hay evidencia a favor de una relación entre Género y balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos incorporar como variable predictora una variable categórica que toma más de dos valores, como por ejemplo ``Ethnicity``:\n",
    "\n",
    "> Balance ~ Ethnicity\n",
    "\n",
    "pero cuidado, **no se trata de codificar** cada valor de la variable categórica con una valor entero distinto:\n",
    "\n",
    "- African American => 1\n",
    "- Caucasian => 2\n",
    "- Asian => 3\n",
    "\n",
    "y luego ajustar un modelo\n",
    "\n",
    "$$\n",
    "\\text{Balance} = \\beta_0 + \\beta_1 x_{\\text{Ethnicity}} + \\varepsilon\n",
    "$$\n",
    "\n",
    "porque estaríamos imponiendo que el efecto de \"Asian\" es el triple que el de \"African American\", en vez de dejar que lo elija el modelo.\n",
    "Lo que hacemos es usar varias variables binarias:\n",
    "\n",
    " - $x_{\\text{Caucasian}}$: vale 1 si es \"Caucasian\", y 0 en cualquiera de los otros dos casos.\n",
    " - $x_{\\text{Asian}}$: vale 1 si es \"Asian\", y 0 en cualquiera de los otros dos casos.\n",
    " \n",
    "El modelo es:\n",
    "\n",
    "$$\n",
    "\\text{Balance} = \\beta_0 + \\beta_1 x_{\\text{Asian}} + \\beta_2 x_{\\text{Caucasian}} + \\varepsilon\n",
    "$$\n",
    " \n",
    "**Pregunta**: ¿por qué no necesitamos otra variable $x_{\\text{African American}}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00021880744304858535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>  531.0000</td> <td>   46.319</td> <td>   11.464</td> <td> 0.000</td> <td>  439.939</td> <td>  622.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ethnicity[T.Asian]</th>     <td>  -18.6863</td> <td>   65.021</td> <td>   -0.287</td> <td> 0.774</td> <td> -146.515</td> <td>  109.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ethnicity[T.Caucasian]</th> <td>  -12.5025</td> <td>   56.681</td> <td>   -0.221</td> <td> 0.826</td> <td> -123.935</td> <td>   98.930</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Balance ~ Ethnicity', credit).fit()\n",
    "print(est.rsquared)\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21501508930450497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>  242.4882</td> <td>   49.567</td> <td>    4.892</td> <td> 0.000</td> <td>  145.040</td> <td>  339.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ethnicity[T.Asian]</th>     <td>    2.4566</td> <td>   57.723</td> <td>    0.043</td> <td> 0.966</td> <td> -111.025</td> <td>  115.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ethnicity[T.Caucasian]</th> <td>    6.6188</td> <td>   50.321</td> <td>    0.132</td> <td> 0.895</td> <td>  -92.312</td> <td>  105.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>                 <td>    6.0507</td> <td>    0.581</td> <td>   10.410</td> <td> 0.000</td> <td>    4.908</td> <td>    7.193</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('Balance ~ Income + Ethnicity', credit).fit()\n",
    "print(est.rsquared)\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Trabajaremos con la tabla `tips.csv`:\n",
    "- Ajusta un modelo lineal a los datos para predecir la propina (tip) en función del resto de columnas: ¿obtienes buenos resultados?\n",
    "- Encuentra el modelo de regresión lineal múltiple que tenga mejor BIC.\n",
    "- ¿Crees que el sexo de la persona que deja la propina es indicativa de si será más o menos generosa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos incluyendo todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        total_bill         tip   sex smoker  day    time        size\n",
       "count   244.000000  244.000000   244    244  244     244  244.000000\n",
       "unique         NaN         NaN     2      2    4       2         NaN\n",
       "top            NaN         NaN  Male     No  Sat  Dinner         NaN\n",
       "freq           NaN         NaN   157    151   87     176         NaN\n",
       "mean     19.785943    2.998279   NaN    NaN  NaN     NaN    2.569672\n",
       "std       8.902412    1.383638   NaN    NaN  NaN     NaN    0.951100\n",
       "min       3.070000    1.000000   NaN    NaN  NaN     NaN    1.000000\n",
       "25%      13.347500    2.000000   NaN    NaN  NaN     NaN    2.000000\n",
       "50%      17.795000    2.900000   NaN    NaN  NaN     NaN    2.000000\n",
       "75%      24.127500    3.562500   NaN    NaN  NaN     NaN    3.000000\n",
       "max      50.810000   10.000000   NaN    NaN  NaN     NaN    6.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = pd.read_csv('tips.csv')\n",
    "tips.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    " - Carga el conjunto ``seaice.csv``, sobre la extensión del hielo polar.\n",
    " - Selecciona sólo los datos de extensión del hielo en el hemisferio norte.\n",
    " - Intenta explicar los datos de extensión del hielo polar en función del año.\n",
    " - Intenta explicar los datos de extensión del hielo polar en función del año y del mes (pero *atención*: ¿cómo tiene sentido incorporar el mes?). ¿El modelo es mejor que el que usa sólo los datos de año?\n",
    " - Usa el modelo para extrapolar la extensión del hielo en el Oceáno Ártico en Julio de 2030, 2040 y 2050.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Nota**: puedes usar `... + C(nombre_variable) + ...` para convertir una variable entera en categórica. Es decir, si ajustamos un modelo\n",
    "\n",
    ">    Extensión del hielo ~ Mes\n",
    "\n",
    "Estamos imponiendo que el efecto del mes de Diciembre es 12 veces el efecto del mes de Enero.\n",
    "\n",
    "Sin embargo, si usamos\n",
    "\n",
    ">    Extensión del hielo ~ C(Mes)\n",
    "\n",
    "Estamos ajustando un modelo\n",
    "\n",
    "$$\n",
    "    E = \\beta_0 + \\beta_1 x_{ENERO} + \\dots + \\beta_{12} x_{DICIEMBRE}  + \\varepsilon\n",
    "$$\n",
    "\n",
    "donde la contribución del mes de Diciembre es independiente de la contribución del efecto del mes de Enero.\n",
    "Observa el ejemplo debajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23860 entries, 0 to 23859\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Year         23860 non-null  int64  \n",
      " 1   Month        23860 non-null  int64  \n",
      " 2   Day          23860 non-null  int64  \n",
      " 3   Extent       23860 non-null  float64\n",
      " 4   Missing      23860 non-null  float64\n",
      " 5   Source Data  23860 non-null  object \n",
      " 6   hemisphere   23860 non-null  object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ice = pd.read_csv('seaice.csv')\n",
    "ice.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Extent</td>      <th>  R-squared:         </th> <td>   0.407</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.407</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8204.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 06 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:41:37</td>     <th>  Log-Likelihood:    </th> <td> -27833.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 11930</td>      <th>  AIC:               </th> <td>5.567e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 11928</td>      <th>  BIC:               </th> <td>5.568e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   15.3628</td> <td>    0.049</td> <td>  313.288</td> <td> 0.000</td> <td>   15.267</td> <td>   15.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month</th>     <td>   -0.6000</td> <td>    0.007</td> <td>  -90.573</td> <td> 0.000</td> <td>   -0.613</td> <td>   -0.587</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>98.579</td> <th>  Durbin-Watson:     </th> <td>   0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  88.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.165</td> <th>  Prob(JB):          </th> <td>7.00e-20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.738</td> <th>  Cond. No.          </th> <td>    16.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Extent   R-squared:                       0.407\n",
       "Model:                            OLS   Adj. R-squared:                  0.407\n",
       "Method:                 Least Squares   F-statistic:                     8204.\n",
       "Date:                Wed, 06 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        10:41:37   Log-Likelihood:                -27833.\n",
       "No. Observations:               11930   AIC:                         5.567e+04\n",
       "Df Residuals:                   11928   BIC:                         5.568e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     15.3628      0.049    313.288      0.000      15.267      15.459\n",
       "Month         -0.6000      0.007    -90.573      0.000      -0.613      -0.587\n",
       "==============================================================================\n",
       "Omnibus:                       98.579   Durbin-Watson:                   0.024\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               88.211\n",
       "Skew:                          -0.165   Prob(JB):                     7.00e-20\n",
       "Kurtosis:                       2.738   Cond. No.                         16.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icen = ice[ice.hemisphere=='north']\n",
    "est = smf.ols('Extent ~ Month', icen).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Extent</td>      <th>  R-squared:         </th> <td>   0.931</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.931</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.464e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 06 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:41:37</td>     <th>  Log-Likelihood:    </th> <td> -14997.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 11930</td>      <th>  AIC:               </th> <td>3.002e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 11918</td>      <th>  BIC:               </th> <td>3.011e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>   14.2833</td> <td>    0.027</td> <td>  529.450</td> <td> 0.000</td> <td>   14.230</td> <td>   14.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.2]</th>  <td>    0.8692</td> <td>    0.039</td> <td>   22.319</td> <td> 0.000</td> <td>    0.793</td> <td>    0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.3]</th>  <td>    1.0235</td> <td>    0.038</td> <td>   26.914</td> <td> 0.000</td> <td>    0.949</td> <td>    1.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.4]</th>  <td>    0.3002</td> <td>    0.038</td> <td>    7.828</td> <td> 0.000</td> <td>    0.225</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.5]</th>  <td>   -1.1077</td> <td>    0.038</td> <td>  -29.120</td> <td> 0.000</td> <td>   -1.182</td> <td>   -1.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.6]</th>  <td>   -2.6843</td> <td>    0.038</td> <td>  -70.000</td> <td> 0.000</td> <td>   -2.759</td> <td>   -2.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.7]</th>  <td>   -5.0957</td> <td>    0.038</td> <td> -133.995</td> <td> 0.000</td> <td>   -5.170</td> <td>   -5.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.8]</th>  <td>   -7.3799</td> <td>    0.038</td> <td> -194.299</td> <td> 0.000</td> <td>   -7.454</td> <td>   -7.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.9]</th>  <td>   -8.1761</td> <td>    0.038</td> <td> -214.032</td> <td> 0.000</td> <td>   -8.251</td> <td>   -8.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.10]</th> <td>   -6.2066</td> <td>    0.038</td> <td> -163.924</td> <td> 0.000</td> <td>   -6.281</td> <td>   -6.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.11]</th> <td>   -3.7340</td> <td>    0.038</td> <td>  -98.117</td> <td> 0.000</td> <td>   -3.809</td> <td>   -3.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Month)[T.12]</th> <td>   -1.5570</td> <td>    0.038</td> <td>  -40.963</td> <td> 0.000</td> <td>   -1.632</td> <td>   -1.483</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>439.024</td> <th>  Durbin-Watson:     </th> <td>   0.136</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 562.805</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.407</td>  <th>  Prob(JB):          </th> <td>6.15e-123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.686</td>  <th>  Cond. No.          </th> <td>    12.9</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Extent   R-squared:                       0.931\n",
       "Model:                            OLS   Adj. R-squared:                  0.931\n",
       "Method:                 Least Squares   F-statistic:                 1.464e+04\n",
       "Date:                Wed, 06 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        10:41:37   Log-Likelihood:                -14997.\n",
       "No. Observations:               11930   AIC:                         3.002e+04\n",
       "Df Residuals:                   11918   BIC:                         3.011e+04\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept         14.2833      0.027    529.450      0.000      14.230      14.336\n",
       "C(Month)[T.2]      0.8692      0.039     22.319      0.000       0.793       0.946\n",
       "C(Month)[T.3]      1.0235      0.038     26.914      0.000       0.949       1.098\n",
       "C(Month)[T.4]      0.3002      0.038      7.828      0.000       0.225       0.375\n",
       "C(Month)[T.5]     -1.1077      0.038    -29.120      0.000      -1.182      -1.033\n",
       "C(Month)[T.6]     -2.6843      0.038    -70.000      0.000      -2.759      -2.609\n",
       "C(Month)[T.7]     -5.0957      0.038   -133.995      0.000      -5.170      -5.021\n",
       "C(Month)[T.8]     -7.3799      0.038   -194.299      0.000      -7.454      -7.305\n",
       "C(Month)[T.9]     -8.1761      0.038   -214.032      0.000      -8.251      -8.101\n",
       "C(Month)[T.10]    -6.2066      0.038   -163.924      0.000      -6.281      -6.132\n",
       "C(Month)[T.11]    -3.7340      0.038    -98.117      0.000      -3.809      -3.659\n",
       "C(Month)[T.12]    -1.5570      0.038    -40.963      0.000      -1.632      -1.483\n",
       "==============================================================================\n",
       "Omnibus:                      439.024   Durbin-Watson:                   0.136\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              562.805\n",
       "Skew:                          -0.407   Prob(JB):                    6.15e-123\n",
       "Kurtosis:                       3.686   Cond. No.                         12.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icen = ice[ice.hemisphere=='north']\n",
    "est = smf.ols('Extent ~ C(Month)', icen).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    " - Carga el conjunto ``simar.csv``, sobre los datos de viento y oleaje de una boya del puerto de Cádiz.\n",
    " - Intenta explicar los datos de altura significativa de ola (Hm0) en función del mes. (pero *atención*: ¿cómo tiene sentido incorporar el mes?).\n",
    " - Intenta explicar los datos de altura significativa de ola (Hm0) en función del mes y de la hora.\n",
    " - Intenta explicar los datos de altura significativa de ola (Hm0) en función del mes, la hora y el año.\n",
    " - ¿Has conseguido un buen modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     AA  MM  DD  HH  Hm0  Tm02    Tp   DirM  Hm0_V  DirM_V  Hm0_F1  Tm02_F1  \\\n",
       "0  2006  12  13  15  0.3  10.9  12.1  272.0    NaN     NaN     NaN      NaN   \n",
       "1  2006  12  13  18  0.3  10.3  12.0  267.0    NaN     NaN     NaN      NaN   \n",
       "2  2006  12  13  21  0.3  10.3  11.8  268.0    NaN     NaN     NaN      NaN   \n",
       "3  2006  12  14   0  0.3  10.7  11.6  271.0    NaN     NaN     NaN      NaN   \n",
       "4  2006  12  14   3  0.3  10.6  11.4  269.0    NaN     NaN     NaN      NaN   \n",
       "\n",
       "   DirM_F1  Hm0_F2  Tm02_F2  DirM_F2  VelV  DirV  \n",
       "0      NaN     NaN      NaN      NaN   NaN   NaN  \n",
       "1      NaN     NaN      NaN      NaN   NaN   NaN  \n",
       "2      NaN     NaN      NaN      NaN   NaN   NaN  \n",
       "3      NaN     NaN      NaN      NaN   NaN   NaN  \n",
       "4      NaN     NaN      NaN      NaN   NaN   NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simar=pd.read_csv('SIMAR_fake.csv')\n",
    "simar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
