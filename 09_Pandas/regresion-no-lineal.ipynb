{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cuaderno de trabajo de:__ Nombre Apellido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión no lineal\n",
    "\n",
    "Concluimos el capítulo 3 del libro [\"Introduction to Statistical Learning\"](http://www-bcf.usc.edu/~gareth/ISL/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bcbc3038fcbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskl_lm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale, PolynomialFeatures\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.metrics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos\n",
    "\n",
    "Cargamos los conjuntos de datos que vamos a usar\n",
    "\n",
    "Los conjuntos de datos están en la web del libro (pero ya están descargados)\n",
    "http://www-bcf.usc.edu/~gareth/ISL/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising = pd.read_csv('advertising.csv', usecols=[1,2,3,4])\n",
    "advertising.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión y ajuste de modelos\n",
    "\n",
    "\n",
    "El análisis de regresión consiste en encontrar un  **modelo** que relaciona los valores medidos de una variable **objetivo** (tb se llama la **respuesta**) en función de un conjunto de variables **explicativas** (tb **variables predictoras**, o **regresores**).\n",
    "\n",
    "Los valores medidos en el mundo real nunca se ajustan de forma perfecta a un modelo, debido en primer lugar a errores de medida, pero también a que cualquier modelo matemático es una *simplificación* del mundo real, y si tuviera en cuenta todos los factores que influyen en un conjunto de variables, sería inmanejable.\n",
    "\n",
    "Por tanto, no tiene sentido aspirar a encontrar un modelo que prediga exactamente los valores medidos, y debemos admitir que el modelo cometerá un cierto error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo útil encuentra una relación funcional sencilla en conjuntos de pocas variables. Se trata de explicar una variable objetivo en función de otro conjunto de variables mejor conocidas o más fáciles de medir. El  **análisis de regresión**  (más exactamente, el análisis de regresión  *paramétrico*) permite encontrar un modelo explicativo en dos etapas:\n",
    "\n",
    "\n",
    " 1. Nuestro conocimiento del tema en cuestión nos permite escribir un modelo que afirma que la variable  *Y*  es una función de las variables $X_1,\\dots,X_p$. La variable  *Y* se suele llamar la **respuesta** y las variables  $X_1,\\dots,X_p$ se llaman  **variables predictoras**. La forma exacta de la función no está fijada a priori, sino que depende de unos pocos  **parámetros**  libres.\n",
    " \n",
    " Por ejemplo, para la **regresión lineal**, el modelo es\n",
    " $$\n",
    " Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon\n",
    " $$\n",
    " donde $\\beta_0,\\dots,\\beta_p$ son los parámetros y $\\epsilon$ es un error que no podemos explicar dentro de este modelo.\n",
    " \n",
    " 2. **Ajustamos el modelo** a los datos de que disponemos, eligiendo los valores de los parámetros para los que la distancia entre los valores medidos de la variable  *Y*  y los valores predichos aplicando el modelo minimizan el error cometido. El error que se suele minimizar es el error cuadrático (**residual sum of squares**):\n",
    "$$\n",
    "RSS = e_1^2 + e_2^2 + \\dots + e_n^2\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "e_1 = y_1 - (\\beta_0 + \\beta_1 x_1), \\dots e_n = y_n - (\\beta_0 + \\beta_1 x_n).\n",
    "$$\n",
    "Es decir, entre todos los posibles coeficientes $\\beta_0,\\dots,\\beta_p$ nos quedamos con aquellos $\\hat{\\beta_0},\\hat{\\beta_1},\\dots,\\hat{\\beta_1}$ que minimizan el RSS, y hemos obtenido la  **regresión lineal por mínimos cuadrados** (**least squares**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de ventas y anuncios\n",
    "\n",
    "Recordamos el modelo lineal\n",
    "\n",
    "$$\n",
    "Sales\\approx \\beta_0 + \\beta_1\\times TV  + \\beta_2\\times radio  + \\varepsilon\n",
    "$$\n",
    "\n",
    "de la sesión anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "X = advertising[['Radio', 'TV']]\n",
    "y = advertising[['Sales']]\n",
    "\n",
    "regr.fit(X,y)\n",
    "print(regr.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dibujar el modelo\n",
    "\n",
    "El número $R^2$ es útil para decidir si el modelo ajusta correctamente, pero puede ser incluso más útil (si es posible) dibujar los datos junto con el ajuste para buscar un patrón. Si observamos dónde falla el modelo, podemos pensar cómo mejorarlo.\n",
    "\n",
    "Por ejemplo, dibujamos la gráfica del ajuste lineal junto con los puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio', advertising).fit()\n",
    "\n",
    "adv = advertising.copy()\n",
    "#Añadimos una columna con los residuos (con signo)\n",
    "adv['res'] = est.resid\n",
    "adv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the min/max values of Radio & TV?\n",
    "# Use these values to set up the grid for plotting.\n",
    "advertising[['Radio', 'TV']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a coordinate grid\n",
    "Radio = np.arange(0,50)\n",
    "TV = np.arange(0,300)\n",
    "\n",
    "B1, B2 = np.meshgrid(Radio, TV, indexing='xy')\n",
    "Z = np.zeros((TV.size, Radio.size))\n",
    "\n",
    "intercept, beta_TV, beta_RADIO = est.params\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "        Z[i,j] =(intercept + B1[i,j]*beta_RADIO + B2[i,j]*beta_TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.suptitle('Regression: Sales ~ Radio + TV', fontsize=20)\n",
    "\n",
    "ax = axes3d.Axes3D(fig)\n",
    "\n",
    "ax.plot_surface(B1, B2, Z, rstride=10, cstride=5, alpha=0.4)\n",
    "adv_plus = adv[adv.res>0]\n",
    "adv_minus = adv[adv.res<=0]\n",
    "ax.scatter3D(adv_plus.Radio, adv_plus.TV, adv_plus.Sales, c='r')\n",
    "ax.scatter3D(adv_minus.Radio, adv_minus.TV, adv_minus.Sales, c='y')\n",
    "\n",
    "ax.set_xlabel('Radio')\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylabel('TV')\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_zlabel('Sales');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, hacemos un dibujo 2d, donde las coordenadas (x,y) de un punto son los valores de inversión en TV y Radio, y el color es el residuo (el error cometido), con signo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non-interactive plot\n",
    "%matplotlib inline \n",
    "#Color oscuro es un residuo negativo\n",
    "#Color claro es un residuo positivo\n",
    "plt.scatter(x=adv.TV, y=adv.Radio, c=adv.res, cmap='Oranges')\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('Radio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El patrón es claro: \n",
    "\n",
    "> El modelo lineal estima las ventas a la baja cuando la inversión en TV y Radio siguen una relación lineal (que a ojo parece que es 5 veces más inversión en TV que en Radio), y estima las ventas al alza cuando la inversión es alta en TV pero baja en Radio, o viceversa.\n",
    "\n",
    "Este patrón puede deberse a que hay una sinergia entre las inversiones en TV y Radio. Es decir: invertir en ambos medios es más eficaz que la suma de los efectos de cada inversión por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables de interacción\n",
    "\n",
    "Podemos ajustar un modelo lineal, pero incluyendo nuevas columnas derivadas de los datos originales, que dependan de las columnas originales de forma no lineal.\n",
    "\n",
    "Por ejemplo, podemos incluir un término de interacción entre las variables TV y Radio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustar un modelo no lineal con statsmodels\n",
    "\n",
    "Para ajustar un modelo no lineal con statsmodels es suficiente con modificar la fórmula:\n",
    "\n",
    "> ``Sales ~ TV + Radio + TV*Radio``\n",
    "\n",
    "Usa como columnas TV, Radio, y el producto de TV y Radio.\n",
    "\n",
    "En este caso, para predecir, tenemos que pasar las columnas ``TV`` y ``Radio``\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'TV':[100,200],\n",
    "    'Radio':[20,30],\n",
    "})\n",
    "est.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ``resistence ~ np.log(speed)``\n",
    "\n",
    "Regresión de la columna ``resistence`` como función del logaritmo de la columna ``speed``.\n",
    "\n",
    "En este caso, para predecir, sólo tenemos que pasar la columna ``speed``\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'speed':[21,22,23,24],\n",
    "})\n",
    "est.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ``Sales ~ TV + np.power(TV,2)``\n",
    "\n",
    "Regresión del modelo cuadrático\n",
    "$$\n",
    "Sales =\\beta_0 + \\beta_1 TV + \\beta_2 TV^2 + \\varepsilon\n",
    "$$\n",
    "\n",
    "En este caso, para predecir, sólo tenemos que pasar la columna ``TV``:\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'TV':[100,200]\n",
    "})\n",
    "est.predict(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de modelos\n",
    "\n",
    "Comparamos los modelos\n",
    "\n",
    "$$\n",
    "Sales =\\beta_0 + \\beta_1 TV + \\beta_2 Radio\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "Sales =\\beta_0 + \\beta_1 TV + \\beta_2 Radio + \\beta_3 TV \\cdot Radio\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio + TV*Radio', advertising).fit()\n",
    "est.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que este modelo supera al modelo 'Sales ~ TV + Radio' en todas las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = smf.ols('Sales ~ TV + Radio', advertising).fit()\n",
    "est.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de mayor grado\n",
    "\n",
    "Ajustamos un modelo lineal a la relación entre el consumo (mpg, miles per galon) y la potencia (horsepower) de vehículos en USA. El modelo lineal no parece capturar bien la relación:\n",
    "\n",
    "$$\n",
    "mpg \\approx \\beta_0 + \\beta_1\\times hp + \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Seaborn's regplot() you can easily plot higher order polynomials.\n",
    "plt.scatter(auto.horsepower, auto.mpg, facecolors='r', edgecolors='k', alpha=0.6, s=20) \n",
    "sns.regplot(auto.horsepower, auto.mpg, ci=None, label='Linear', scatter=False)\n",
    "plt.legend()\n",
    "plt.ylim(5,55)\n",
    "plt.xlim(40,240);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que un modelo cuadrático ajusta mucho mejor.\n",
    "$$\n",
    "mpg \\approx \\beta_0 + \\beta_1\\times hp + \\beta_1\\times hp^2 + \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Seaborn's regplot() you can easily plot higher order polynomials.\n",
    "plt.scatter(auto.horsepower, auto.mpg, facecolors='r', edgecolors='k', alpha=0.6, s=20) \n",
    "sns.regplot(auto.horsepower, auto.mpg, ci=None, label='Linear', scatter=False)\n",
    "sns.regplot(auto.horsepower, auto.mpg, ci=None, label='Degree 2', order=2, scatter=False)\n",
    "plt.legend()\n",
    "plt.ylim(5,55)\n",
    "plt.xlim(40,240);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, aumentar el grado del polinomio hará que ajustemos demasiado bien el *\"ruido\"*. Este fenónemo se denomina **overfitting**.\n",
    "\n",
    "- El modelo tiene un error bajo en nuestro conjunto de datos.\n",
    "- Cuando intentamos aplicar el modelo a una observación que no pertenece al conjunto original, la predicción es descabellada.\n",
    "\n",
    "> *Si ajustamos un modelo con más coeficientes que observaciones, el ajuste será perfecto, pero el modelo es inútil.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With Seaborn's regplot() you can easily plot higher order polynomials.\n",
    "plt.scatter(auto.horsepower, auto.mpg, facecolors='r', edgecolors='k', alpha=0.6, s=20) \n",
    "sns.regplot(auto.horsepower, auto.mpg, ci=None, label='Linear', scatter=False)\n",
    "sns.regplot(auto.horsepower, auto.mpg, ci=None, label='Degree 2', order=2, scatter=False)\n",
    "sns.regplot(auto.horsepower, auto.mpg, ci=None, label='Degree 5', order=5, scatter=False)\n",
    "plt.legend()\n",
    "plt.ylim(5,55)\n",
    "plt.xlim(40,240);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustar un modelo polinomial con scikit-learn\n",
    "\n",
    "Para ajustar un modelo polinomial vamos a usar otra componente fundamental de ``scikit-learn``: el **preprocesado**, en este caso para conseguir las potencias de la columna ``horsepower``, usamos un objeto ``PolynomialFeatures``, que tiene un método ``fit_transform``, que aplicamos tanto al ajustar el modelo como al hacer predicciones:\n",
    "\n",
    "```python\n",
    "order=2\n",
    "poly = PolynomialFeatures(order)\n",
    "X = poly.fit_transform(auto[['horsepower']])\n",
    "y = auto['mpg']\n",
    "\n",
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "regr.fit(X,y)\n",
    "\n",
    "regr.predict(poly.fit_transform(250))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolando con un modelo de orden alto\n",
    "\n",
    "Probemos a usar los modelos polinomiales de distinto orden para predecir el valor de ``mpg`` para un coche de 250 HP de potencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for order in [1,2,3,4,5]:\n",
    "    poly = PolynomialFeatures(order)\n",
    "    X = poly.fit_transform(auto[['horsepower']])\n",
    "    y = auto['mpg']\n",
    "\n",
    "    regr = skl_lm.LinearRegression()\n",
    "\n",
    "    regr.fit(X,y)\n",
    "\n",
    "    print('grado',order,':', regr.predict(poly.fit_transform([[250]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misma info, pero de forma gráfica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 250\n",
    "\n",
    "Lx = max(auto.horsepower) - min(auto.horsepower)\n",
    "xmin, xmax = min(auto.horsepower) - Lx/10, max(auto.horsepower) + Lx/10\n",
    "xmax = max(xmax, x_new+Lx/10)\n",
    "\n",
    "\n",
    "X = auto[['horsepower']]\n",
    "y = auto['mpg']\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(auto.horsepower, auto.mpg, facecolors='r', edgecolors='k', alpha=0.6, s=20)\n",
    "colors = 'rgbcmyk'\n",
    "for order in range(1,6):\n",
    "    poly = PolynomialFeatures(order)\n",
    "    X = poly.fit_transform(auto[['horsepower']])\n",
    "\n",
    "    regr = skl_lm.LinearRegression()\n",
    "\n",
    "    regr.fit(X,y)\n",
    "\n",
    "    regr.predict(poly.fit_transform([[250]]))\n",
    "\n",
    "    #xs son puntos equiespaciados entre xmin y xmax\n",
    "    xs = np.arange(xmin, xmax, Lx/100)\n",
    "    #ys es el resultado de aplicar el modelo a cada punto de xs\n",
    "    ys = regr.predict(poly.fit_transform(xs.reshape(-1,1)))\n",
    "    #asi que plot(xs,ys) dibuja la grafica del modelo mpg = f(hp)\n",
    "    plt.plot(xs, ys, \n",
    "             label='order %d'%order, \n",
    "             color=colors[order%(len(colors))])\n",
    "    #Resaltamos la prediccion para hp=250\n",
    "    plt.scatter([x_new], regr.predict(poly.fit_transform([[x_new]])), \n",
    "                facecolors=colors[order%(len(colors))],\n",
    "                edgecolors='k', alpha=0.6, s=20)\n",
    "    plt.legend()\n",
    "#plt.ylim(ymin,ymax)\n",
    "plt.xlim(xmin,xmax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regplot con bandas de confianza\n",
    "\n",
    "Hemos visto que los resultados al extrapolar dependen fuertemente del modelo escogido. Sin embargo, si usamos modelos de distinto orden para predecir el valor de ``mpg`` de un coche cuya potencia está dentro del rango de nuestro conjunto de datos los resultados no varían tanto.\n",
    "\n",
    "Otra forma de saber si nos podemos fiar del modelo es pedir a ``regplot`` que dibuje bandas de error alrededor del modelo que ha ajustado. Estas bandas se obtienen mediante el método de **bootstrap**, que en vez de ajustar un modelo ajusta muchos, a distintos subconjuntos de los datos, y comprueba si todos esos modelos arrojan predicciones similares o dispares.\n",
    "\n",
    "No le daremos más vuelo a esta idea. Si a alguien le interesa, que pida más referencias (puede leer el capítulo 5.2 del [Introduction to Statistical Learning](https://www.clinicadentalordonez.com/clinicas.php)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for order in [1,2,3,4,6]:\n",
    "    plt.scatter(auto.horsepower, auto.mpg, facecolors='r', edgecolors='k', alpha=0.6, s=20) \n",
    "    sns.regplot(auto.horsepower, auto.mpg, ci=95, label='Degree %d'%order, order=order, scatter=False)\n",
    "    plt.legend()\n",
    "    plt.ylim(5,55)\n",
    "    plt.xlim(40,240);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observamos que las bandas de error se mantienen bajo control dentro del rango de los datos, pero se disparan cuando usamos el modelo para extrapolar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos \"train\" y \"test\"\n",
    "\n",
    "Vamos a hacer este análisis de forma un poco más sistemática, introduciendo además un concepto nuevo: los conjuntos de **entrenamiento (train set)** y **evaluación (test set)**:\n",
    "\n",
    " - **train set**: Se usa para ajustar el modelo.\n",
    " - **test set**: *No* se usa para ajustar el modelo, sino *únicamente* para comprobar el error que comete el modelo ajustado en el conjunto *train*.\n",
    "\n",
    "> *¿Cómo los obtenemos?*\n",
    "\n",
    "Antes de hacer el análisis, *dividimos nuestros datos en los dos conjuntos*:\n",
    " - Podemos asignar cada dato a ``train`` o a ``test`` **de forma aleatoria**.\n",
    " - Podemos asignar los datos a ``train`` o a ``test`` **siguiendo un criterio** concreto que tenga sentido. Por ejemplo, los datos hasta el 2017 son para train, y los datos de 2017 son para test. Puede tener sentido si vamos a usar el modelo para extrapolar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La funcion train_test_split reparte un conjunto en dos partes\n",
    "# train y test, de forma aleatoria\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = auto[['horsepower']]\n",
    "y = auto['mpg']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Entrenamos el modelo *sólo con el conjunto de entrenamiento*.\n",
    " - Calculamos el error cuadrático medio que comete el modelo en los conjuntos de train y de test:\n",
    "\n",
    "\n",
    "```python \n",
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "def error_cuadratico_medio(regr, x, y):\n",
    "    return sum((regr.predict(x) - y)**2)/len(y)\n",
    "\n",
    "print(error_cuadratico_medio(regr, X_train, y_train))\n",
    "print(error_cuadratico_medio(regr, X_test, y_test))\n",
    "```\n",
    "\n",
    "No usamos el $R^2$, porque compara el error cuadrático medio de nuestro modelo con la varianza del conjunto ``y_test``, pero la varianza es el error cuadrático medio que comete el modelo \"constante\" igual a ``y_test.mean()``, (la media de ``y_test``), y no es una comparación justa, porque nuestro modelo no puede usar los datos de ``y_test``, sino únicamente los datos de ``y_train``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "def error_cuadratico_medio(regr, x, y):\n",
    "    return sum((regr.predict(x) - y)**2)/len(y)\n",
    "\n",
    "print(error_cuadratico_medio(regr, X_train, y_train))\n",
    "print(error_cuadratico_medio(regr, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos lo anterior para modelos de varios grados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_order = 15\n",
    "\n",
    "X = auto[['horsepower']].values\n",
    "y = auto['mpg']\n",
    "for order in range(1,max_order):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25)\n",
    "    plt.scatter(X_train[:,0], y_train, \n",
    "                facecolors='r', edgecolors='k', alpha=0.6, s=20,\n",
    "                label='train')\n",
    "    plt.scatter(X_test[:,0], y_test,\n",
    "                facecolors='g', edgecolors='k', alpha=0.6, s=20,\n",
    "                label='test')\n",
    "    sns.regplot(X_train[:,0], y_train, ci=None, label='Degree %d'%order, order=order, scatter=False)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos esta información de forma numérica, pero en vez de quedarnos con una descomposición (train, test), repetimos N veces y tomamos el promedio de los errores cuadráticos medios. Se puede mejorar, pero nos da una idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#\n",
    "N = 40\n",
    "max_order = 20\n",
    "\n",
    "y = auto['mpg']\n",
    "\n",
    "for order in range(1,max_order):\n",
    "    poly = PolynomialFeatures(order)\n",
    "    X = poly.fit_transform( auto[['horsepower']])\n",
    "    sum_scores = 0\n",
    "    sum_scores2 = 0\n",
    "    for _ in range(N):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.25)\n",
    "        regr = skl_lm.LinearRegression()\n",
    "        regr.fit(X_train,y_train)\n",
    "        sum_scores += error_cuadratico_medio(regr, X_test, y_test)\n",
    "    print(order,':',sum_scores/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el modelo no aumenta su poder predictivo de forma significativa cuando aumentamos el orden del modelo por encima de 2, aunque el error no decae de forma severa hasta que no llegamos a orden 10, aproximadamente.\n",
    "\n",
    "Sin embargo, si pensamos usar el modelo para extrapolar, es importante comprobar que el modelo funcione bien cuando extrapolamos, y para ello *no debemos elegir el conjunto de test al azar*.\n",
    "\n",
    "Observemos qué ocurre si tomamos como conjunto de test los 40 vehículos de mayor potencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.sort_values(by='horsepower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 5\n",
    "split_index = len(auto) - 40\n",
    "\n",
    "X = auto[['horsepower']].values\n",
    "y = auto['mpg']\n",
    "\n",
    "#xs son puntos equiespaciados entre xmin y xmax\n",
    "xs = np.arange(xmin, xmax, Lx/100)\n",
    "\n",
    "for order in range(1,max_order):\n",
    "    X_train, X_test = X[:split_index,:], X[split_index:,:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    poly = PolynomialFeatures(order)\n",
    "    Xpower = poly.fit_transform(X_train)\n",
    "\n",
    "    regr = skl_lm.LinearRegression()\n",
    "\n",
    "    regr.fit(Xpower, y_train)\n",
    "\n",
    "    #ys es el resultado de aplicar el modelo a cada punto de xs\n",
    "    ys = regr.predict(poly.fit_transform(xs.reshape(-1,1)))\n",
    "    #asi que plot(xs,ys) dibuja la grafica del modelo mpg = f(hp)\n",
    "    plt.plot(xs, ys, label='order %d'%order)\n",
    "    \n",
    "    plt.scatter(X_train[:,0], y_train, \n",
    "                facecolors='r', edgecolors='k', alpha=0.6, s=20,\n",
    "                label='train')\n",
    "    plt.scatter(X_test[:,0], y_test,\n",
    "                facecolors='g', edgecolors='k', alpha=0.6, s=20,\n",
    "                label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el error cuando entrenamos con los 352 primeros vehículos e intentamos predecir el mpg de los 40 vehículos de mayor potencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 10\n",
    "split_index = len(auto) - 40\n",
    "\n",
    "y = auto['mpg']\n",
    "\n",
    "for order in range(1,max_order):\n",
    "    poly = PolynomialFeatures(order)\n",
    "    X = poly.fit_transform( auto[['horsepower']])\n",
    "    X_train, X_test = X[:split_index,:], X[split_index:,:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    regr = skl_lm.LinearRegression()\n",
    "    regr.fit(X_train,y_train)\n",
    "    print(order,':',error_cuadratico_medio(regr, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción mejora al pasar de un modelo de orden 1 a un modelo de orden 2, pero empeora si seguimos aumentado el orden del modelo.\n",
    "\n",
    "> _Extrapolar es mucho más difícil que interpolar_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    " - Carga el conjunto ``seaice.csv``, sobre la extensión del hielo polar.\n",
    " - Selecciona sólo los datos de extensión del hielo en el hemisferio norte.\n",
    " - Intenta explicar los datos de extensión del hielo polar en función del año y el mes, tomando el mes como variable categórica.\n",
    " - Añade a lo anterior el año al cuadrado como variable explicativa, para tener un modelo cuadrático del año, y manteniendo el mes como variable categórica. ¿Qué signo tiene el coeficiente del término año al cuadrado? ¿Puedes interpretar el signo de este coeficiente como una indicación de que la pérdida de hielo en el ártico se está acelerando o se está frenando?\n",
    " - Usa el modelo cuadrático para extrapolar la extensión del hielo en el Oceáno Ártico en Agosto de 2030, 2040 y 2050. Compara el resultado con los obtenidos para el modelo lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sugerencia**: Usa statsmodel y `... + C(nombre_variable) + ...` para convertir una variable entera en categórica, como hiciste la semana pasada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice = pd.read_csv('seaice.csv')\n",
    "ice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    " - Sobre el mismo dataset ``seaice.csv``.\n",
    " - Selecciona sólo los datos de extensión del hielo en el hemisferio norte y sólo los datos de los meses de Agosto.\n",
    " - Ajusta modelos polinomiales que expliquen la extensión del hielo Ártico en Agosto, en función del año, pero de distintos órdenes.\n",
    " - Divide los datos en conjuntos ``train`` y ``test``, de modo que ``train`` contenga entradas hasta una cierta fecha (2005, por ejemplo), y ``test`` contenga el resto. Decide cuál es el orden para el que el modelo extrapola mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    " - Carga el conjunto ``yacht_hydrodynamics.csv``, sobre características hidrodinámicas de ciertos cascos de yate medidas en canal de ensayos.\n",
    " - Ajusta un modelo lineal para la resistencia, usando como única variable explicativa el número de Froude.\n",
    " - Ajusta un modelo polinómico para la resistencia, usando como única variable explicativa el número de Froude.\n",
    " - Compara de alguna manera los modelos anteriores.\n",
    " - Intenta hacer predicciones de resistencia para número de Froude 0.5 y 0.6: ¿tienen sentido esas predicciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht = pd.read_csv('yacht_hydrodynamics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glosario en inglés\n",
    "\n",
    "- **regresión**: *regression*\n",
    "- **sobreajuste**: *overfitting*\n",
    "- **conjunto de entrenamiento**: *train set*\n",
    "- **conjunto de evaluación**: *test set*\n",
    "- **ajustar un modelo**: *fit a model*\n",
    "- **hacer predicciones**: *make predictions*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
